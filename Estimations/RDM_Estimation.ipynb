{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5a720b-af17-4312-b543-71f603ddfa23",
   "metadata": {
    "id": "04ab4fbd-f191-427a-a2e4-db4ff76fa385"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c40530b-0436-4965-908d-e709114e316b",
   "metadata": {
    "executionInfo": {
     "elapsed": 3102,
     "status": "ok",
     "timestamp": 1651313252929,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "42e504d1-66bf-459a-bdee-ef0f268a7b81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmdstanpy \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import json\n",
    "from utils.random import random_rdm_2A\n",
    "from utils.utils import get_dfs, calculate_waic, bci, plot_mean_posterior\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fda25d-8c73-4076-a32e-b9f64a89752d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"] + plt.rcParams[\"font.serif\"]\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"pdf.use14corefonts\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5ed11-783c-476d-b190-95c7356783ca",
   "metadata": {},
   "source": [
    "## Choose Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5ad7e-f13d-41a9-a8d5-528f99513a33",
   "metadata": {},
   "source": [
    "#### roots and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c30c41-a570-411a-a874-36f0776f87f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = \"../\"\n",
    "plots_root = \"Results/hierarchical/Plots/\"\n",
    "datasets_root = root + \"Datasets/\"\n",
    "behavioural_data_root = datasets_root +  \"behavioral_data/selected_data/\" \n",
    "stan_files_root = root +  \"models/stan/\" \n",
    "saved_models_root = \"Results/hierarchical/stan_results/\"\n",
    "\n",
    "model_config = {}\n",
    "plots_path = \"\"\n",
    "dataset_path = \"\"\n",
    "stan_file_path = \"\"\n",
    "stan_output_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fddb96-7bae-4d47-a322-e42e6285e69e",
   "metadata": {},
   "source": [
    "#### read models configuration json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272c3c67-1630-4266-9163-296e244195b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../models/rdm_based_models.json\") as f:\n",
    "    models = json.load(f)\n",
    "    models_name = list(models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768a530-f38b-4267-9084-5ba80a1471af",
   "metadata": {},
   "source": [
    "#### Choose and set model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8122cea8-7777-4a9c-98be-4fea9b2dfcab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50d60d5df7845af8a9155382c737b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('RDM_cd', 'RDM_ndm', 'ANN-RDM_l_FT', 'ANN-RD…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def SetModelAndPaths(model_name):\n",
    "    global model_config\n",
    "    global plots_path\n",
    "    global dataset_path\n",
    "    global stan_file_path\n",
    "    global stan_output_dir\n",
    "    model_config = models[model_name]\n",
    "    plots_path = plots_root + model_config[\"plots_folder_name\"] + \"/\"\n",
    "    dataset_path = datasets_root + \"AI Models Results/\" + model_config[\"dataset_name\"]\n",
    "    stan_file_path = stan_files_root + model_config[\"stan_file\"]\n",
    "    stan_output_dir = saved_models_root + model_config[\"model_name\"] + \"/\"\n",
    "    \n",
    "    if not os.path.exists(plots_path):\n",
    "        os.makedirs(plots_path)\n",
    "        print(\"Directory \" , plots_path ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , plots_path ,  \" already exists\")\n",
    "        \n",
    "    if not os.path.exists(stan_output_dir):\n",
    "        os.makedirs(stan_output_dir)\n",
    "        print(\"Directory \" , stan_output_dir ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , stan_output_dir ,  \" already exists\")\n",
    "\n",
    "widgets.interact(SetModelAndPaths, model_name=models_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3e1780-916e-4904-a2d3-389b27227c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ANN-RDM_s_am_BERT',\n",
       " 'stan_file': 'ANN-RDM/sigmoid_am.stan',\n",
       " 'dataset_name': 'BERT.csv',\n",
       " 'plots_folder_name': 'ANN-RDM_am_BERT',\n",
       " 'transf_params': ['transf_mu_alpha',\n",
       "  'transf_mu_b',\n",
       "  'transf_mu_threshold_word',\n",
       "  'transf_mu_threshold_nonword',\n",
       "  'transf_mu_ndt',\n",
       "  'transf_mu_k_1',\n",
       "  'transf_mu_k_2']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e617f6",
   "metadata": {
    "id": "123c4809-7b46-4f8d-b578-0d5e9fb5fbe7"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d41247-a08b-4710-a8cb-006ca5ace314",
   "metadata": {},
   "source": [
    "Loading words and non-words with zipf and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6417ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1651313252934,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "72172233-0e82-4058-8a5c-8657e9fe4693",
    "outputId": "35336463-3bb2-41e5-c84f-7c34fdcfc77d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>freq</th>\n",
       "      <th>label</th>\n",
       "      <th>zipf</th>\n",
       "      <th>category</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>non_word_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prayerfally</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>9.978092e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exceptions</td>\n",
       "      <td>8780</td>\n",
       "      <td>1</td>\n",
       "      <td>3.459151</td>\n",
       "      <td>HF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.506832e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enter</td>\n",
       "      <td>36407</td>\n",
       "      <td>1</td>\n",
       "      <td>4.472820</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.023243e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haze</td>\n",
       "      <td>937</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183929</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.990428</td>\n",
       "      <td>9.572419e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hicked</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.244391</td>\n",
       "      <td>7.556091e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74312</th>\n",
       "      <td>shipmates</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.835902</td>\n",
       "      <td>LF</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>1.679315e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74313</th>\n",
       "      <td>omnivorous</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>1.768955</td>\n",
       "      <td>LF</td>\n",
       "      <td>0.840428</td>\n",
       "      <td>1.595716e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74314</th>\n",
       "      <td>throttled</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1.893894</td>\n",
       "      <td>LF</td>\n",
       "      <td>0.869104</td>\n",
       "      <td>1.308963e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74315</th>\n",
       "      <td>tav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>9.905907e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74316</th>\n",
       "      <td>unfinished</td>\n",
       "      <td>1349</td>\n",
       "      <td>1</td>\n",
       "      <td>3.547107</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>5.224134e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74317 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            string   freq  label      zipf category  word_prob  non_word_prob\n",
       "0      prayerfally      0      0  0.000000       NW   0.002191   9.978092e-01\n",
       "1       exceptions   8780      1  3.459151       HF   1.000000   2.506832e-07\n",
       "2            enter  36407      1  4.472820       HF   0.999980   2.023243e-05\n",
       "3             haze    937      1  3.183929       HF   0.990428   9.572419e-03\n",
       "4           hicked      0      0  0.000000       NW   0.244391   7.556091e-01\n",
       "...            ...    ...    ...       ...      ...        ...            ...\n",
       "74312    shipmates     99      1  2.835902       LF   0.998321   1.679315e-03\n",
       "74313   omnivorous     84      1  1.768955       LF   0.840428   1.595716e-01\n",
       "74314    throttled    156      1  1.893894       LF   0.869104   1.308963e-01\n",
       "74315          tav      0      0  0.000000       NW   0.009409   9.905907e-01\n",
       "74316   unfinished   1349      1  3.547107       HF   0.999995   5.224134e-06\n",
       "\n",
       "[74317 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_nword_df = pd.read_csv(dataset_path, header=None,\n",
    "                            names =[\"string\", \"freq\",  \"label\", \"zipf\",\n",
    "                                    \"category\", \"word_prob\", \"non_word_prob\"])\n",
    "word_nword_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb6266a",
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1651313252938,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "f37d4118-f2ea-4691-bff9-02f1ac1cebbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading LDT Data\n",
    "behavioural_df = pd.read_csv(behavioural_data_root + \"LDT_data.csv\",\n",
    "                             header=None,\n",
    "                             names=[\"accuracy\", \"rt\", \"string\", \"response\",\n",
    "                                    \"participant\", \"minRT\", \"participant_id\"])\n",
    "# Merging  behavioral dataframe with word_nonword_df to have words and non-words data with behavioral data\n",
    "behavioural_df = pd.merge(behavioural_df, word_nword_df, on=\"string\", how=\"left\").dropna().reset_index(drop=True)\n",
    "behavioural_df = behavioural_df.drop([\"freq\", \"participant\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c791ac-26e5-4ee4-929e-379e1b3248df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>rt</th>\n",
       "      <th>string</th>\n",
       "      <th>response</th>\n",
       "      <th>minRT</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>zipf</th>\n",
       "      <th>category</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>non_word_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>sand</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.307194</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>7.448991e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.462</td>\n",
       "      <td>textbook</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.344913</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>5.534554e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>carmed</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>9.780724e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.503</td>\n",
       "      <td>pain</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.990457</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>7.514760e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.513</td>\n",
       "      <td>technical</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.916116</td>\n",
       "      <td>HF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.702559e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy     rt     string  response  minRT  participant_id  label  \\\n",
       "0         1  0.422       sand         1  0.422               1    1.0   \n",
       "1         1  0.462   textbook         1  0.422               1    1.0   \n",
       "2         0  0.490     carmed         1  0.422               1    0.0   \n",
       "3         1  0.503       pain         1  0.422               1    1.0   \n",
       "4         1  0.513  technical         1  0.422               1    1.0   \n",
       "\n",
       "       zipf category  word_prob  non_word_prob  \n",
       "0  4.307194       HF   0.999993   7.448991e-06  \n",
       "1  3.344913       HF   0.999995   5.534554e-06  \n",
       "2  0.000000       NW   0.021928   9.780724e-01  \n",
       "3  4.990457       HF   0.999925   7.514760e-05  \n",
       "4  3.916116       HF   1.000000   5.702559e-08  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavioural_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837f7f89-8b4c-4cc5-9c2c-43dd3a512561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reducing size of dataframe for testing purposes\n",
    "behavioural_df = behavioural_df.loc[behavioural_df[\"participant_id\"].isin(np.arange(2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2e8433-5198-455c-a3e2-b5ce9c59f51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>rt</th>\n",
       "      <th>string</th>\n",
       "      <th>response</th>\n",
       "      <th>minRT</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>zipf</th>\n",
       "      <th>category</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>non_word_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>sand</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.307194</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>7.448991e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.462</td>\n",
       "      <td>textbook</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.344913</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>5.534554e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>carmed</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>9.780724e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.503</td>\n",
       "      <td>pain</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.990457</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>7.514760e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.513</td>\n",
       "      <td>technical</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.916116</td>\n",
       "      <td>HF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.702559e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1</td>\n",
       "      <td>1.340</td>\n",
       "      <td>creatoon's</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>9.983045e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1</td>\n",
       "      <td>1.372</td>\n",
       "      <td>ricochet</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.689774</td>\n",
       "      <td>LF</td>\n",
       "      <td>0.998222</td>\n",
       "      <td>1.778390e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>1.392</td>\n",
       "      <td>transformation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.300434</td>\n",
       "      <td>HF</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>7.078020e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>1.423</td>\n",
       "      <td>gompiles</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>9.987220e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>1.435</td>\n",
       "      <td>pispassionately</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>9.829358e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy     rt           string  response  minRT  participant_id  label  \\\n",
       "0           1  0.422             sand         1  0.422               1    1.0   \n",
       "1           1  0.462         textbook         1  0.422               1    1.0   \n",
       "2           0  0.490           carmed         1  0.422               1    0.0   \n",
       "3           1  0.503             pain         1  0.422               1    1.0   \n",
       "4           1  0.513        technical         1  0.422               1    1.0   \n",
       "..        ...    ...              ...       ...    ...             ...    ...   \n",
       "367         1  1.340       creatoon's         0  0.422               1    0.0   \n",
       "368         1  1.372         ricochet         1  0.422               1    1.0   \n",
       "369         1  1.392   transformation         1  0.422               1    1.0   \n",
       "370         1  1.423         gompiles         0  0.422               1    0.0   \n",
       "371         1  1.435  pispassionately         0  0.422               1    0.0   \n",
       "\n",
       "         zipf category  word_prob  non_word_prob  \n",
       "0    4.307194       HF   0.999993   7.448991e-06  \n",
       "1    3.344913       HF   0.999995   5.534554e-06  \n",
       "2    0.000000       NW   0.021928   9.780724e-01  \n",
       "3    4.990457       HF   0.999925   7.514760e-05  \n",
       "4    3.916116       HF   1.000000   5.702559e-08  \n",
       "..        ...      ...        ...            ...  \n",
       "367  0.000000       NW   0.001695   9.983045e-01  \n",
       "368  2.689774       LF   0.998222   1.778390e-03  \n",
       "369  3.300434       HF   0.999929   7.078020e-05  \n",
       "370  0.000000       NW   0.001278   9.987220e-01  \n",
       "371  0.000000       NW   0.017064   9.829358e-01  \n",
       "\n",
       "[372 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavioural_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6ff4c",
   "metadata": {
    "id": "ff61f25e-7817-4f3f-a48f-d5a6666b0e75",
    "tags": []
   },
   "source": [
    "## Stan Model and Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0a87-ed95-486a-beec-87a50c2f86ef",
   "metadata": {},
   "source": [
    "Compiling stan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60550ee7-157d-4393-9f12-773eb947efce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93380,
     "status": "ok",
     "timestamp": 1651313346844,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "c1b3627d-0ea2-49b6-86f0-7b098a5a16d6",
    "outputId": "4bc8643c-82c0-4fc9-99a0-7f232fa1eea4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdm_model = cmdstanpy.CmdStanModel(model_name=model_config[\"model_name\"],\n",
    "                                   stan_file=stan_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c8503-9cb2-40c0-ae79-e0e8d386a86f",
   "metadata": {},
   "source": [
    "Preparing model\"s inputs\n",
    "\n",
    "note that some inputs of data_dict might not be used depending on which model is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd38af62-fefa-4440-b250-f1717e0a2937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = len(behavioural_df)                                                    # For all models\n",
    "participant = behavioural_df[\"participant_id\"].to_numpy()                     # For all models\n",
    "p = behavioural_df.loc[:, [\"word_prob\", \"non_word_prob\"]].to_numpy()       # predicted probabilites of words and non-words, for ANN-EAM models\n",
    "frequency = behavioural_df[\"zipf\"].to_numpy().astype(int)                  # zipf values, for models with non-decision time or drift modulation\n",
    "frequencyCondition = behavioural_df[\"category\"].replace([\"HF\", \"LF\", \"NW\"], [1, 2, 3]).to_numpy() # For models with conditional drift\n",
    "response = behavioural_df[\"response\"].to_numpy().astype(int)               # for all models\n",
    "rt = behavioural_df[\"rt\"].to_numpy()                                       # for all models\n",
    "minRT = behavioural_df[\"minRT\"].to_numpy()                                 # for all models\n",
    "RTbound = 0.1                                                              # for all models\n",
    "Number_Of_Participants = len(set(behavioural_df[\"participant_id\"]))\n",
    "\n",
    "threshold_priors = [2, 1, 1, 1]          # For all models with LBA\n",
    "ndt_priors = [0, 0.5, 1, 1];               # For models wtihout non-decision time modulation\n",
    "g_priors = [-2, 1, 0, 1]                 # For models wtih non-decision time modulation\n",
    "m_priors = [0, 0.5, 0, 1]                # For models wtih non-decision time modulation\n",
    "drift_priors = [1, 2, 1, 1]              # For models without drift mapping functions (non ANN-EAM models)\n",
    "alpha_priors = [0, 1, 1, 1]              # For models with drift mapping functions\n",
    "b_priors = [0, 1, 1, 1]                  # For models with drift mapping functions with asymptote modulation and linear models\n",
    "k_priors = [2, 1, 1, 1]                  # For models with sigmoid drift mapping functions (ANN-EAM models)\n",
    "\n",
    "# define input for the model\n",
    "data_dict = {\"N\": N,\n",
    "             \"L\": Number_Of_Participants,\n",
    "             \"participant\": participant,\n",
    "             \"response\": response,\n",
    "             \"rt\": rt,\n",
    "             \"minRT\": minRT,\n",
    "             \"RTbound\": RTbound,\n",
    "             \"frequency\": frequency,\n",
    "             \"frequencyCondition\": frequencyCondition,\n",
    "             \"threshold_priors\": threshold_priors,\n",
    "             \"ndt_priors\": ndt_priors,\n",
    "             \"g_priors\": g_priors,\n",
    "             \"m_priors\": m_priors,\n",
    "             \"drift_priors\": drift_priors,\n",
    "             \"p\": p,\n",
    "             \"alpha_priors\": alpha_priors,\n",
    "             \"b_priors\": b_priors,\n",
    "             \"k_priors\": k_priors,\n",
    "             }\n",
    "\n",
    "# set sampling parameters\n",
    "n_iter = 1000\n",
    "n_warmup = int(n_iter/2)\n",
    "n_sample = int(n_iter/2)\n",
    "n_chains = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4034d3d-99d8-43bf-b744-6b0608141c8d",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ddd68e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "edac015c-18f4-4ebf-8c3c-ecaf4b8e1d6a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:04:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:04:39 - cmdstanpy - INFO - Chain [2] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [2] method = sample (Default)Chain [1] method = sample (Default)\n",
      "\n",
      "Chain [1] sample\n",
      "Chain [1] num_samples = 500\n",
      "Chain [1] num_warmup = 500\n",
      "Chain [1] save_warmup = 0 (Default)\n",
      "Chain [1] thin = 1 (Default)\n",
      "Chain [1] adapt\n",
      "Chain [1] engaged = 1 (Default)\n",
      "Chain [1] gamma = 0.050000000000000003 (Default)\n",
      "Chain [1] delta = 0.80000000000000004 (Default)\n",
      "Chain [1] kappa = 0.75 (Default)\n",
      "Chain [1] t0 = 10 (Default)\n",
      "Chain [1] init_buffer = 75 (Default)\n",
      "Chain [1] term_buffer = 50 (Default)\n",
      "Chain [1] window = 25 (Default)\n",
      "Chain [1] algorithm = hmc (Default)\n",
      "Chain [1] hmc\n",
      "Chain [2] sample\n",
      "Chain [2] num_samples = 500\n",
      "Chain [2] num_warmup = 500\n",
      "Chain [2] save_warmup = 0 (Default)\n",
      "Chain [2] thin = 1 (Default)\n",
      "Chain [2] adapt\n",
      "Chain [2] engaged = 1 (Default)\n",
      "Chain [2] gamma = 0.050000000000000003 (Default)\n",
      "Chain [2] delta = 0.80000000000000004 (Default)\n",
      "Chain [2] kappa = 0.75 (Default)\n",
      "Chain [2] t0 = 10 (Default)\n",
      "Chain [2] init_buffer = 75 (Default)\n",
      "Chain [2] term_buffer = 50 (Default)\n",
      "Chain [2] window = 25 (Default)\n",
      "Chain [2] algorithm = hmc (Default)\n",
      "Chain [2] hmc\n",
      "Chain [2] engine = nuts (Default)\n",
      "Chain [2] nuts\n",
      "Chain [2] max_depth = 10 (Default)\n",
      "Chain [1] engine = nuts (Default)\n",
      "Chain [2] metric = diag_e (Default)\n",
      "Chain [2] metric_file =  (Default)\n",
      "Chain [2] stepsize = 1 (Default)\n",
      "Chain [2] stepsize_jitter = 0 (Default)\n",
      "Chain [2] num_chains = 1 (Default)\n",
      "Chain [1] nuts\n",
      "Chain [1] max_depth = 10 (Default)\n",
      "Chain [1] metric = diag_e (Default)\n",
      "Chain [1] metric_file =  (Default)\n",
      "Chain [1] stepsize = 1 (Default)\n",
      "Chain [2] id = 2\n",
      "Chain [2] data\n",
      "Chain [2] file = C:\\Users\\Arash\\AppData\\Local\\Temp\\tmpohm9e21d\\xp27f23a.json\n",
      "Chain [2] init = 2 (Default)\n",
      "Chain [2] random\n",
      "Chain [2] seed = 61406\n",
      "Chain [2] output\n",
      "Chain [2] file = E:\\Workspace\\Thesis\\ANN-EAM\\Estimations\\Results\\hierarchical\\stan_results\\ANN-RDM_s_am_BERT\\ANN-RDM_s_am_BERT-20230907100439_2.csv\n",
      "Chain [2] diagnostic_file =  (Default)\n",
      "Chain [2] refresh = 100 (Default)\n",
      "Chain [2] sig_figs = -1 (Default)\n",
      "Chain [2] profile_file = profile.csv (Default)\n",
      "Chain [2] num_threads = 1 (Default)\n",
      "Chain [2] \n",
      "Chain [1] stepsize_jitter = 0 (Default)\n",
      "Chain [1] num_chains = 1 (Default)\n",
      "Chain [1] id = 1 (Default)\n",
      "Chain [1] data\n",
      "Chain [1] file = C:\\Users\\Arash\\AppData\\Local\\Temp\\tmpohm9e21d\\xp27f23a.json\n",
      "Chain [1] init = 2 (Default)\n",
      "Chain [1] random\n",
      "Chain [1] seed = 61406\n",
      "Chain [1] output\n",
      "Chain [1] file = E:\\Workspace\\Thesis\\ANN-EAM\\Estimations\\Results\\hierarchical\\stan_results\\ANN-RDM_s_am_BERT\\ANN-RDM_s_am_BERT-20230907100439_1.csv\n",
      "Chain [1] diagnostic_file =  (Default)\n",
      "Chain [1] refresh = 100 (Default)\n",
      "Chain [1] sig_figs = -1 (Default)\n",
      "Chain [1] profile_file = profile.csv (Default)\n",
      "Chain [1] num_threads = 1 (Default)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [2] \n",
      "Chain [2] Gradient evaluation took 0.000916 seconds\n",
      "Chain [2] 1000 transitions using 10 leapfrog steps per transition would take 9.16 seconds.\n",
      "Chain [1] Gradient evaluation took 0.000877 seconds\n",
      "Chain [1] 1000 transitions using 10 leapfrog steps per transition would take 8.77 seconds.\n",
      "Chain [2] Adjust your expectations accordingly!\n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [1] Adjust your expectations accordingly!\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [2] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [2] Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Chain [2] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [2] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [2] \n",
      "Chain [2] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [2] Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Chain [2] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [2] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [2] \n",
      "Chain [2] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [2] Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Chain [2] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [2] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [2] \n",
      "Chain [1] Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain [2] Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain [1] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [1] Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Chain [1] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [1] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [1] \n",
      "Chain [2] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [2] Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Chain [2] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [2] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [2] \n",
      "Chain [2] Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Chain [2] Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Chain [2] If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "Chain [2] but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Chain [2] \n",
      "Chain [2] Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain [1] Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain [2] Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain [1] Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain [2] Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain [1] Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain [2] Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain [1] Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain [1] Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain [1] Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain [2] Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain [2] Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain [1] Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain [2] Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain [1] Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain [2] Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain [1] Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain [1] Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain [2] Iteration: 800 / 1000 [ 80%]  (Sampling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:06:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [1] Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain [1] \n",
      "Chain [1] Elapsed Time: 66.41 seconds (Warm-up)\n",
      "Chain [1] 60.941 seconds (Sampling)\n",
      "Chain [1] 127.351 seconds (Total)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [2] Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain [2] Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain [2] \n",
      "Chain [2] Elapsed Time: 69.681 seconds (Warm-up)\n",
      "Chain [2] 84.239 seconds (Sampling)\n",
      "Chain [2] 153.92 seconds (Total)\n",
      "Chain [2] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:07:13 - cmdstanpy - INFO - Chain [2] done processing\n",
      "10:07:13 - cmdstanpy - WARNING - Non-fatal error during sampling:\n",
      "Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Exception: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "\tException: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "\tException: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "\tException: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "\tException: sigmoid_am_model_namespace::log_prob: drift_word_t[3] is nan, but must be greater than or equal to 0.000000 (in 'E:/Workspace/Thesis/ANN-EAM/models/stan/ANN-RDM/sigmoid_am.stan', line 111, column 4 to column 36)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n"
     ]
    }
   ],
   "source": [
    "fit = rdm_model.sample(data=data_dict,\n",
    "                       iter_sampling=n_sample, \n",
    "                       iter_warmup=n_warmup,\n",
    "                       chains=n_chains,\n",
    "                       output_dir=stan_output_dir,\n",
    "                       show_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e1d2a-6f23-41c6-bf4d-360f7280b9e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading Model\n",
    "\n",
    "(In case model have been fitted before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a33d647",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "d781cdef-a1c6-4af1-940c-824398ec7d2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit = cmdstanpy.from_csv(stan_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7bfe3-f4b0-4c5e-b38a-da896fc9910a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b4b9f0",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a8e1d56e-e7e4-4ca1-a0bd-5b34edf6ea44",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***hmc diagnostics:\n",
      "Processing csv files: E:\\Workspace\\Thesis\\ANN-EAM\\Estimations\\Results\\hierarchical\\stan_results\\ANN-RDM_s_am_BERT\\ANN-RDM_s_am_BERT-20230907100439_1.csv, E:\\Workspace\\Thesis\\ANN-EAM\\Estimations\\Results\\hierarchical\\stan_results\\ANN-RDM_s_am_BERT\\ANN-RDM_s_am_BERT-20230907100439_2.csv\n",
      "\n",
      "Checking sampler transitions treedepth.\n",
      "Treedepth satisfactory for all transitions.\n",
      "\n",
      "Checking sampler transitions for divergences.\n",
      "No divergent transitions found.\n",
      "\n",
      "Checking E-BFMI - sampler transitions HMC potential energy.\n",
      "E-BFMI satisfactory.\n",
      "\n",
      "Effective sample size satisfactory.\n",
      "\n",
      "Split R-hat values satisfactory all parameters.\n",
      "\n",
      "Processing complete, no problems detected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"***hmc diagnostics:\")\n",
    "print(fit.diagnose(), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b033c45b",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "efa2a6ff-ad48-4c7e-a094-4c645923644e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***DF: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MCSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>N_Eff/s</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lp__</th>\n",
       "      <td>-4.985910</td>\n",
       "      <td>0.221645</td>\n",
       "      <td>3.859360</td>\n",
       "      <td>-11.703300</td>\n",
       "      <td>-4.730770</td>\n",
       "      <td>0.831432</td>\n",
       "      <td>303.189</td>\n",
       "      <td>2.08184</td>\n",
       "      <td>1.004850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu_ndt</th>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.410663</td>\n",
       "      <td>-0.709866</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.670029</td>\n",
       "      <td>936.989</td>\n",
       "      <td>6.43382</td>\n",
       "      <td>0.999556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu_threshold_word</th>\n",
       "      <td>1.641740</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>0.726875</td>\n",
       "      <td>0.571940</td>\n",
       "      <td>1.589780</td>\n",
       "      <td>2.959530</td>\n",
       "      <td>477.293</td>\n",
       "      <td>3.27732</td>\n",
       "      <td>1.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu_threshold_nonword</th>\n",
       "      <td>2.015740</td>\n",
       "      <td>0.026641</td>\n",
       "      <td>0.704573</td>\n",
       "      <td>0.838247</td>\n",
       "      <td>1.997170</td>\n",
       "      <td>3.233890</td>\n",
       "      <td>699.414</td>\n",
       "      <td>4.80251</td>\n",
       "      <td>0.999418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu_alpha</th>\n",
       "      <td>0.183286</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>-1.092770</td>\n",
       "      <td>0.198235</td>\n",
       "      <td>1.368460</td>\n",
       "      <td>832.572</td>\n",
       "      <td>5.71684</td>\n",
       "      <td>0.999062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[368]</th>\n",
       "      <td>-2.314620</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.237629</td>\n",
       "      <td>-2.707950</td>\n",
       "      <td>-2.305920</td>\n",
       "      <td>-1.939400</td>\n",
       "      <td>1116.070</td>\n",
       "      <td>7.66350</td>\n",
       "      <td>1.002090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[369]</th>\n",
       "      <td>-3.526970</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.340001</td>\n",
       "      <td>-4.101770</td>\n",
       "      <td>-3.520740</td>\n",
       "      <td>-2.980670</td>\n",
       "      <td>998.437</td>\n",
       "      <td>6.85575</td>\n",
       "      <td>1.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[370]</th>\n",
       "      <td>-5.212650</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.532799</td>\n",
       "      <td>-6.067520</td>\n",
       "      <td>-5.207430</td>\n",
       "      <td>-4.355590</td>\n",
       "      <td>952.633</td>\n",
       "      <td>6.54124</td>\n",
       "      <td>1.001610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[371]</th>\n",
       "      <td>-2.948260</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.296896</td>\n",
       "      <td>-3.442260</td>\n",
       "      <td>-2.943920</td>\n",
       "      <td>-2.476500</td>\n",
       "      <td>1110.240</td>\n",
       "      <td>7.62341</td>\n",
       "      <td>1.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[372]</th>\n",
       "      <td>-3.039280</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.305564</td>\n",
       "      <td>-3.547330</td>\n",
       "      <td>-3.034800</td>\n",
       "      <td>-2.552600</td>\n",
       "      <td>1109.860</td>\n",
       "      <td>7.62082</td>\n",
       "      <td>1.002080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2268 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Mean      MCSE    StdDev         5%       50%  \\\n",
       "lp__                 -4.985910  0.221645  3.859360 -11.703300 -4.730770   \n",
       "mu_ndt                0.001785  0.013416  0.410663  -0.709866  0.005191   \n",
       "mu_threshold_word     1.641740  0.033271  0.726875   0.571940  1.589780   \n",
       "mu_threshold_nonword  2.015740  0.026641  0.704573   0.838247  1.997170   \n",
       "mu_alpha              0.183286  0.026056  0.751843  -1.092770  0.198235   \n",
       "...                        ...       ...       ...        ...       ...   \n",
       "log_lik[368]         -2.314620  0.007113  0.237629  -2.707950 -2.305920   \n",
       "log_lik[369]         -3.526970  0.010760  0.340001  -4.101770 -3.520740   \n",
       "log_lik[370]         -5.212650  0.017262  0.532799  -6.067520 -5.207430   \n",
       "log_lik[371]         -2.948260  0.008910  0.296896  -3.442260 -2.943920   \n",
       "log_lik[372]         -3.039280  0.009172  0.305564  -3.547330 -3.034800   \n",
       "\n",
       "                           95%     N_Eff  N_Eff/s     R_hat  \n",
       "lp__                  0.831432   303.189  2.08184  1.004850  \n",
       "mu_ndt                0.670029   936.989  6.43382  0.999556  \n",
       "mu_threshold_word     2.959530   477.293  3.27732  1.000080  \n",
       "mu_threshold_nonword  3.233890   699.414  4.80251  0.999418  \n",
       "mu_alpha              1.368460   832.572  5.71684  0.999062  \n",
       "...                        ...       ...      ...       ...  \n",
       "log_lik[368]         -1.939400  1116.070  7.66350  1.002090  \n",
       "log_lik[369]         -2.980670   998.437  6.85575  1.002370  \n",
       "log_lik[370]         -4.355590   952.633  6.54124  1.001610  \n",
       "log_lik[371]         -2.476500  1110.240  7.62341  1.002080  \n",
       "log_lik[372]         -2.552600  1109.860  7.62082  1.002080  \n",
       "\n",
       "[2268 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fit.summary()\n",
    "\n",
    "print(\"***DF: \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0302aa3b",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b33a48e1-8c3b-4668-9e74-ba74c58e3bec",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Rhat > 1.01: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "print(\"***Rhat > 1.01: \")\n",
    "for f in df[\"R_hat\"]:\n",
    "    if f >= 1.01 or f <= 0.9:\n",
    "        counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54606c2d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "681ed2bf-2a28-4a8b-90d0-24b9fede846f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"R_hat\"]>1.01].to_csv(\"Results/hierarchical/logs/\" + model_config[\"model_name\"] + \"_rhat_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f94b558-e3ad-4a0a-b779-c389bc960922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MCSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>N_Eff/s</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Mean, MCSE, StdDev, 5%, 50%, 95%, N_Eff, N_Eff/s, R_hat]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"R_hat\"]>1.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0aa820a",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a651e5b7-b7f1-4426-ae8e-f9e236eb6e91",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MCSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>N_Eff/s</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean  MCSE  StdDev   5%  50%  95%  N_Eff  N_Eff/s  R_hat\n",
       "count   0.0   0.0     0.0  0.0  0.0  0.0    0.0      0.0    0.0\n",
       "mean    NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN\n",
       "std     NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN\n",
       "min     NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN\n",
       "25%     NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN\n",
       "50%     NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN\n",
       "75%     NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN\n",
       "max     NaN   NaN     NaN  NaN  NaN  NaN    NaN      NaN    NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"R_hat\"]>1.01].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32ef5c",
   "metadata": {
    "id": "2743cc7e-7238-4f84-afe4-4b502770f62b",
    "tags": []
   },
   "source": [
    "## Check parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc740f54-db93-410c-9e26-282710ef2024",
   "metadata": {},
   "source": [
    "Parameters posterior plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67254033",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "48fc6630-74be-47a0-b387-ec99b9dc4b47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_posterior(fit, var_names=model_config[\"transf_params\"], hdi_prob=.95);\n",
    "plt.savefig(plots_path + \"Parameters.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49f9c5",
   "metadata": {},
   "source": [
    "Loading model parameters for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133df71d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3539c070-29f7-422d-8c2e-1f7d44ef9246",
    "tags": []
   },
   "outputs": [],
   "source": [
    "drift_word_t = fit.stan_variables()[\"drift_word_t\"]\n",
    "drift_nonword_t = fit.stan_variables()[\"drift_nonword_t\"]\n",
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    threshold_t_word = fit.stan_variables()[\"threshold_t_word\"]\n",
    "    threshold_t_nonword = fit.stan_variables()[\"threshold_t_nonword\"]\n",
    "else:\n",
    "    threshold_t = fit.stan_variables()[\"threshold_t\"]\n",
    "ndt_t = fit.stan_variables()[\"ndt_t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaeee5d-28e4-4b67-9d90-6d8ba5d39423",
   "metadata": {},
   "source": [
    "#### Models mean parameters in different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645f86a",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3a247d68-c3af-49ef-91fd-ba4ea221358d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_condition_w = drift_word_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "HF_condition_nw = drift_nonword_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "LF_condition_w = drift_word_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "LF_condition_nw = drift_nonword_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "NW_condition_w = drift_word_t[:, behavioural_df[\"category\"]==\"NW\"]\n",
    "NW_condition_nw = drift_nonword_t[:, behavioural_df[\"category\"]==\"NW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e000d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "deac1183-5610-4a19-8ff8-7bace8d12e7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"HF words, word drift mean and std:\")\n",
    "print(np.mean(np.mean(HF_condition_w, axis=1)), np.std(np.mean(HF_condition_w, axis=1)))\n",
    "print(\"HF words, nonword drift mean and std:\")\n",
    "print(np.mean(np.mean(HF_condition_nw, axis=1)), np.std(np.mean(HF_condition_nw, axis=1)))\n",
    "print(\"LF words word drift mean and std:\")\n",
    "print(np.mean(np.mean(LF_condition_w, axis=1)), np.std(np.mean(LF_condition_w, axis=1)))\n",
    "print(\"LF words nonword drift mean and std:\")\n",
    "print(np.mean(np.mean(LF_condition_nw, axis=1)), np.std(np.mean(LF_condition_nw, axis=1)))\n",
    "print(\"NW words word drift mean and std:\")\n",
    "print(np.mean(np.mean(NW_condition_w, axis=1)), np.std(np.mean(NW_condition_w, axis=1)))\n",
    "print(\"NW words nonword drift mean and std:\")\n",
    "print(np.mean(np.mean(NW_condition_nw, axis=1)), np.std(np.mean(NW_condition_nw, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84308d46-e368-491f-8532-0f2b7b4f9966",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3a247d68-c3af-49ef-91fd-ba4ea221358d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    HF_condition_w = threshold_t_word[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "    HF_condition_nw = threshold_t_nonword[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "    LF_condition_w = threshold_t_word[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "    LF_condition_nw = threshold_t_nonword[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "    NW_condition_w = threshold_t_word[:, behavioural_df[\"category\"]==\"NW\"]\n",
    "    NW_condition_nw = threshold_t_nonword[:, behavioural_df[\"category\"]==\"NW\"]\n",
    "else:\n",
    "    HF_condition = threshold_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "    LF_condition = threshold_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "    NW_condition = threshold_t[:, behavioural_df[\"category\"]==\"NW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d462da-a2d7-403e-9e79-1bcfd84251db",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "deac1183-5610-4a19-8ff8-7bace8d12e7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    print(\"HF words, word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(HF_condition_w, axis=1)), np.std(np.mean(HF_condition_w, axis=1)))\n",
    "    print(\"HF words, nonword threshold mean and std:\")\n",
    "    print(np.mean(np.mean(HF_condition_nw, axis=1)), np.std(np.mean(HF_condition_nw, axis=1)))\n",
    "    print(\"LF words word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(LF_condition_w, axis=1)), np.std(np.mean(LF_condition_w, axis=1)))\n",
    "    print(\"LF words nonword threshold mean and std:\")\n",
    "    print(np.mean(np.mean(LF_condition_nw, axis=1)), np.std(np.mean(LF_condition_nw, axis=1)))\n",
    "    print(\"NW words word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(NW_condition_w, axis=1)), np.std(np.mean(NW_condition_w, axis=1)))\n",
    "    print(\"NW words nonword threshold mean and std:\")\n",
    "    print(np.mean(np.mean(NW_condition_nw, axis=1)), np.std(np.mean(NW_condition_nw, axis=1)))\n",
    "else:\n",
    "    print(\"HF words, threshold mean and std:\")\n",
    "    print(np.mean(np.mean(HF_condition, axis=1)), np.std(np.mean(HF_condition, axis=1)))\n",
    "    print(\"LF words, threshold mean and std:\")\n",
    "    print(np.mean(np.mean(LF_condition, axis=1)), np.std(np.mean(LF_condition, axis=1)))\n",
    "    print(\"NW words, word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(NW_condition, axis=1)), np.std(np.mean(NW_condition, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e74a9",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "06aceb06-2f53-47ae-b0f8-68d0c96f3cbf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_condition = ndt_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "LF_condition = ndt_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "NW_condition = ndt_t[:, behavioural_df[\"category\"]==\"NW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacfbe0",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "c7ff4f51-0587-4f7a-bf79-7bc1fe0951e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"HF words ndt_t mean and std:\")\n",
    "print(np.mean(np.mean(HF_condition, axis=1)), np.std(np.mean(HF_condition, axis=1)))\n",
    "print(\"LF words ndt_t mean and std:\")\n",
    "print(np.mean(np.mean(LF_condition, axis=1)), np.std(np.mean(LF_condition, axis=1)))\n",
    "print(\"Non Words ndt_t mean and std:\")\n",
    "print(np.mean(np.mean(NW_condition, axis=1)), np.std(np.mean(NW_condition, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64f181-de50-4bec-ad6a-9f0c7c95cea5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beabf75-4cb8-49dc-b604-9f0adf32dfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_likelihood = fit.stan_variables()[\"log_lik\"]\n",
    "print(calculate_waic(log_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23772b-94de-40e6-88d6-f5a6aaefab64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simulating RDM with estimated parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867e05c-ebda-4bc3-ae51-e340e337344f",
   "metadata": {},
   "source": [
    "Simulating RDM with estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6786ed3-265f-4698-9a37-75d19e125806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    pp_rt, pp_response = random_rdm_2A(drift_word_t, drift_nonword_t, threshold_t_word, threshold_t_nonword, ndt_t, noise_constant=1, dt=0.001, max_rt=5)\n",
    "else:\n",
    "    pp_rt, pp_response = random_rdm_2A(drift_word_t, drift_nonword_t, threshold_t, threshold_t, ndt_t, noise_constant=1, dt=0.001, max_rt=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c05ed84d-ea5f-4fd7-893e-028d8bdea5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save RT and Response arrays\n",
    "with open(f'Results/Simulations/{model_config[\"model_name\"]}.npy', 'wb') as f:\n",
    "    np.save(f, pp_rt)\n",
    "    np.save(f, pp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e406e-621b-42a2-9216-217c44f73917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(f'Results/Simulations/{model_config[\"model_name\"]}.npy', 'rb') as f:\n",
    "#     pp_rt = np.load(f)\n",
    "#     pp_response = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ffc14-42ef-4338-9f7e-f6ad3851989c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicted Data\n",
    "tmp1 = pd.DataFrame(pp_rt,\n",
    "                    index=pd.Index(np.arange(1, len(pp_rt)+1), name=\"sample\"),\n",
    "                    columns=pd.MultiIndex.from_product(([\"rt\"],\n",
    "                                                        np.arange(pp_rt.shape[1])),\n",
    "                                                        names=[\"variable\", \"trial\"]))\n",
    "tmp2 = pd.DataFrame(pp_response,\n",
    "                    index=pd.Index(np.arange(1, len(pp_response)+1), name=\"sample\"),\n",
    "                    columns=pd.MultiIndex.from_product(([\"response\"],\n",
    "                                                        np.arange(pp_response.shape[1])),\n",
    "                                                               names=[\"variable\", \"trial\"]))\n",
    "predictedData = pd.concat((tmp1, tmp2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e2ea5-cc95-44ff-929d-90a18cfdf61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68071a-3121-47da-94c5-bae5db334c5c",
   "metadata": {
    "id": "defea622-f638-4a0e-a269-937234d4a49f",
    "tags": []
   },
   "source": [
    "## RT Quantiles Posterior Predictions Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378eb36-76cc-4a39-b2ed-643addccbc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantiles = [.1, .3, .5, .7, .9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02a18b-7bf1-40c1-b4e6-9db867ed685f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### All Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9228d-9765-4f44-a0ef-c97b6fd2e4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_all_trials, pred_all_trials = get_dfs(behavioural_df, predictedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726b938-0a09-4b6e-a072-f459566b1c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_quantiles_ex = exp_all_trials[\"rt\"].quantile(quantiles)\n",
    "all_quantiles_pred = pred_all_trials.quantile(quantiles, axis=1).T\n",
    "all_predicted_bci = np.array([bci(all_quantiles_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9684dde-03ae-4332-ae06-c1db2ed85527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "ax.set_title(\"All Trials quantiles\", fontweight=\"bold\", size=14)\n",
    "ax.scatter(quantiles, all_quantiles_ex, color=\"black\", s=100)\n",
    "\n",
    "ax.fill_between(quantiles,\n",
    "                all_predicted_bci[:, 0],\n",
    "                all_predicted_bci[:, 1],\n",
    "                all_predicted_bci[:, 0] < all_predicted_bci[:, 1],  color = \"orange\", alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Quantiles\", fontsize=14)\n",
    "ax.set_xticks(quantiles)\n",
    "ax.set_xticklabels(quantiles)\n",
    "ax.set_ylabel(\"RT\", fontsize=14)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(12)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(12) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-All Trials.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29ef22-e1ea-4549-b5fd-db69f2cc698f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### All Trials (word response vs non-word response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e21b6-8fe0-4783-8100-78fc59ca10bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_word_resp_all, pred_word_resp_all = get_dfs(behavioural_df, predictedData,\n",
    "                                                response=1)\n",
    "exp_nonword_resp_all, pred_nonword_resp_all = get_dfs(behavioural_df, predictedData,\n",
    "                                                      response=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ff6be-9135-4ddf-bf21-43b130426f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_quantiles_ex = exp_word_resp_all[\"rt\"].quantile(quantiles)\n",
    "nonword_quantiles_ex = exp_nonword_resp_all[\"rt\"].quantile(quantiles)\n",
    "\n",
    "word_quantiles_pred = pred_word_resp_all.quantile(quantiles, axis=1).T\n",
    "nonword_quantiles_pred = pred_nonword_resp_all.quantile(quantiles, axis=1).T\n",
    "\n",
    "word_predicted_bci = np.array([bci(word_quantiles_pred[x]) for x in quantiles])\n",
    "nonword_predicted_bci = np.array([bci(nonword_quantiles_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843d560-1a77-428a-9084-4a3dbdff62ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25,6))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"Word trials quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[1].set_title(\"Non Word trials quantiles\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0].scatter(quantiles, word_quantiles_ex, color=\"black\", s=100)\n",
    "axes[1].scatter(quantiles, nonword_quantiles_ex, color=\"black\", s=100)\n",
    "\n",
    "axes[0].fill_between(quantiles,\n",
    "                word_predicted_bci[:, 0],\n",
    "                word_predicted_bci[:, 1],\n",
    "                word_predicted_bci[:, 0] < word_predicted_bci[:, 1],  color = \"tomato\", alpha=0.5)\n",
    "\n",
    "axes[1].fill_between(quantiles,\n",
    "                nonword_predicted_bci[:, 0],\n",
    "                nonword_predicted_bci[:, 1],\n",
    "                nonword_predicted_bci[:, 0] < nonword_predicted_bci[:, 1],  color = \"powderblue\", alpha=0.5)\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=16)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RT\", fontsize=16)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-All Trials-Word vs Nonword.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f9bf4-b8a0-4ae2-a379-2181b7273a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### All trials (Correct Choice vs Incorrect Choice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a15b2-057b-4038-ad71-32cc17d5f2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_cor_choice_all, _ = get_dfs(behavioural_df, predictedData,\n",
    "                                accuracy=1)\n",
    "exp_incor_resp_all, _ = get_dfs(behavioural_df, predictedData,\n",
    "                                accuracy=0)\n",
    "pred_cor_choice_all = predictedData[\"rt\"][predictedData[\"response\"]==behavioural_df[\"label\"]]\n",
    "pred_incor_choice_all = predictedData[\"rt\"][predictedData[\"response\"]!=behavioural_df[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4dfe2-00fe-4644-91e3-8fb946a95fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cor_quantiles_ex = exp_cor_choice_all[\"rt\"].quantile(quantiles)\n",
    "incor_quantiles_ex = exp_incor_resp_all[\"rt\"].quantile(quantiles)\n",
    "\n",
    "cor_quantiles_pred = pred_cor_choice_all.quantile(quantiles, axis=1).T\n",
    "incor_quantiles_pred = pred_incor_choice_all.quantile(quantiles, axis=1).T\n",
    "\n",
    "cor_predicted_bci = np.array([bci(cor_quantiles_pred[x]) for x in quantiles])\n",
    "incor_predicted_bci = np.array([bci(incor_quantiles_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfde7cd-d40a-40a2-af5e-752f6b2fea1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25,6))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"Correct choice quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[1].set_title(\"Incorrect choice quantiles\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0].scatter(quantiles, cor_quantiles_ex, color=\"black\", s=100)\n",
    "axes[1].scatter(quantiles, incor_quantiles_ex, color=\"black\", s=100)\n",
    "\n",
    "axes[0].fill_between(quantiles,\n",
    "                cor_predicted_bci[:, 0],\n",
    "                cor_predicted_bci[:, 1],\n",
    "                cor_predicted_bci[:, 0] < cor_predicted_bci[:, 1],  color = \"coral\", alpha=0.5)\n",
    "\n",
    "axes[1].fill_between(quantiles,\n",
    "                incor_predicted_bci[:, 0],\n",
    "                incor_predicted_bci[:, 1],\n",
    "                incor_predicted_bci[:, 0] < incor_predicted_bci[:, 1],  color = \"palegreen\", alpha=0.5)\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=14)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RTs upper boundary\", fontsize=14)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-All Trials-Correct vs Incorrect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf2c17-b464-4994-bec4-36387026a780",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional (HF, LF, NW trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d60ee5-9e44-4e7b-b22f-e9b85fb2fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_HF_trials, pred_HF_trials = get_dfs(behavioural_df, predictedData,\n",
    "                                        category=\"HF\")\n",
    "exp_LF_trials, pred_LF_trials = get_dfs(behavioural_df, predictedData,\n",
    "                                        category=\"LF\")\n",
    "exp_NW_trials, pred_NW_trials = get_dfs(behavioural_df, predictedData,\n",
    "                                        category=\"NW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96001a51-55af-4f25-93c4-cdcc00556eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experiment Data quantile\n",
    "HF_quantile_ex = exp_HF_trials[\"rt\"].quantile(quantiles)\n",
    "LF_quantile_ex = exp_LF_trials[\"rt\"].quantile(quantiles)\n",
    "NW_quantile_ex = exp_NW_trials[\"rt\"].quantile(quantiles)\n",
    "\n",
    "# predicted data quantiles (for each sample)\n",
    "HF_quantile_pred = pred_HF_trials.quantile(quantiles, axis=1).T\n",
    "LF_quantile_pred = pred_LF_trials.quantile(quantiles, axis=1).T\n",
    "NW_quantile_pred = pred_NW_trials.quantile(quantiles, axis=1).T\n",
    "\n",
    "# predicted data quantiles bci\n",
    "HF_predicted_bci = np.array([bci(HF_quantile_pred[x]) for x in quantiles])\n",
    "LF_predicted_bci = np.array([bci(LF_quantile_pred[x]) for x in quantiles])\n",
    "NW_predicted_bci = np.array([bci(NW_quantile_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40fa75-a52a-45f9-8f44-b6097ff621e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3 , figsize=(25,5))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"HF quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[1].set_title(\"LF quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[2].set_title(\"NW quantiles\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0].scatter(quantiles, HF_quantile_ex, color=\"black\", s=100)\n",
    "axes[1].scatter(quantiles, LF_quantile_ex, color=\"black\", s=100)\n",
    "axes[2].scatter(quantiles, NW_quantile_ex, color=\"black\", s=100)\n",
    "\n",
    "axes[0].fill_between(quantiles,\n",
    "                HF_predicted_bci[:, 0],\n",
    "                HF_predicted_bci[:, 1],\n",
    "                HF_predicted_bci[:, 0] < HF_predicted_bci[:, 1],  color = \"gold\", alpha=0.3)\n",
    "\n",
    "axes[1].fill_between(quantiles,\n",
    "                LF_predicted_bci[:, 0],\n",
    "                LF_predicted_bci[:, 1],\n",
    "                LF_predicted_bci[:, 0] < LF_predicted_bci[:, 1],  color = \"lightskyblue\", alpha=0.3)\n",
    "\n",
    "axes[2].fill_between(quantiles,\n",
    "                NW_predicted_bci[:, 0],\n",
    "                NW_predicted_bci[:, 1],\n",
    "                NW_predicted_bci[:, 0] < NW_predicted_bci[:, 1],  color = \"limegreen\", alpha=0.3)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=18)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RTs upper boundary\", fontsize=18)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label1.set_fontsize(13)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-Conditional.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c0620-716b-4051-b343-c1e711a969b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conditional (HF, LF, NW trials) for word response and nonword response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f552f-53a6-4f8a-b00a-b05244c8323d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_word_resp_HF, pred_word_resp_HF = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"HF\", response=1)\n",
    "exp_word_resp_LF, pred_word_resp_LF = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"LF\", response=1)\n",
    "exp_word_resp_NW, pred_word_resp_NW = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"NW\", response=1)\n",
    "\n",
    "exp_nonword_resp_HF, pred_nonword_resp_HF = get_dfs(behavioural_df, predictedData,\n",
    "                                                    category=\"HF\", response=0)\n",
    "exp_nonword_resp_LF, pred_nonword_resp_LF = get_dfs(behavioural_df, predictedData,\n",
    "                                                    category=\"LF\", response=0)\n",
    "exp_nonword_resp_NW, pred_nonword_resp_NW = get_dfs(behavioural_df, predictedData,\n",
    "                                                    category=\"NW\", response=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c6f5c-416a-4576-b75c-a2d9d3307b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experiment Data quantile\n",
    "HF_word_quantile_ex = exp_word_resp_HF[\"rt\"].quantile(quantiles)\n",
    "LF_word_quantile_ex = exp_word_resp_LF[\"rt\"].quantile(quantiles)\n",
    "NW_word_quantile_ex = exp_word_resp_NW[\"rt\"].quantile(quantiles)\n",
    "\n",
    "HF_nonword_quantile_ex = exp_nonword_resp_HF[\"rt\"].quantile(quantiles)\n",
    "LF_nonword_quantile_ex = exp_nonword_resp_LF[\"rt\"].quantile(quantiles)\n",
    "NW_nonword_quantile_ex = exp_nonword_resp_NW[\"rt\"].quantile(quantiles)\n",
    "\n",
    "# predicted data quantiles (for each sample)\n",
    "HF_word_quantile_pred = pred_word_resp_HF.quantile(quantiles, axis=1).T\n",
    "LF_word_quantile_pred = pred_word_resp_LF.quantile(quantiles, axis=1).T\n",
    "NW_word_quantile_pred = pred_word_resp_NW.quantile(quantiles, axis=1).T\n",
    "\n",
    "HF_nonword_quantile_pred = pred_nonword_resp_HF.quantile(quantiles, axis=1).T\n",
    "LF_nonword_quantile_pred = pred_nonword_resp_LF.quantile(quantiles, axis=1).T\n",
    "NW_nonword_quantile_pred = pred_nonword_resp_NW.quantile(quantiles, axis=1).T\n",
    "\n",
    "\n",
    "# predicted data quantiles bci\n",
    "HF_word_predicted_bci = np.array([bci(HF_word_quantile_pred[x]) for x in quantiles])\n",
    "LF_word_predicted_bci = np.array([bci(LF_word_quantile_pred[x]) for x in quantiles])\n",
    "NW_word_predicted_bci = np.array([bci(NW_word_quantile_pred[x]) for x in quantiles])\n",
    "\n",
    "HF_nonword_predicted_bci = np.array([bci(HF_nonword_quantile_pred[x]) for x in quantiles])\n",
    "LF_nonword_predicted_bci = np.array([bci(LF_nonword_quantile_pred[x]) for x in quantiles])\n",
    "NW_nonword_predicted_bci = np.array([bci(NW_nonword_quantile_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbc3a4-c5a0-4d3d-8038-dae9c80a4830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3 , figsize=(30,10))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axes[0][0].set_title(\"HF quantiles word choice\", fontweight=\"bold\", size=20)\n",
    "axes[0][1].set_title(\"LF quantiles word choice\", fontweight=\"bold\", size=20)\n",
    "axes[0][2].set_title(\"NW quantiles word choice\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[1][0].set_title(\"HF quantiles non-word choice\", fontweight=\"bold\", size=20)\n",
    "axes[1][1].set_title(\"LF quantiles non-word choice\", fontweight=\"bold\", size=20)\n",
    "axes[1][2].set_title(\"NW quantiles non-word choice\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0][0].scatter(quantiles, HF_word_quantile_ex, color=\"black\", s=90)\n",
    "axes[0][1].scatter(quantiles, LF_word_quantile_ex, color=\"black\", s=90)\n",
    "axes[0][2].scatter(quantiles, NW_word_quantile_ex, color=\"black\", s=90)\n",
    "\n",
    "axes[1][0].scatter(quantiles, HF_nonword_quantile_ex, color=\"black\", s=90)\n",
    "axes[1][1].scatter(quantiles, LF_nonword_quantile_ex, color=\"black\", s=90)\n",
    "axes[1][2].scatter(quantiles, NW_nonword_quantile_ex, color=\"black\", s=90)\n",
    "\n",
    "\n",
    "axes[0][0].fill_between(quantiles,\n",
    "                HF_word_predicted_bci[:, 0],\n",
    "                HF_word_predicted_bci[:, 1],\n",
    "                HF_word_predicted_bci[:, 0] < HF_word_predicted_bci[:, 1],  color = \"gold\", alpha=0.3)\n",
    "\n",
    "axes[0][1].fill_between(quantiles,\n",
    "                LF_word_predicted_bci[:, 0],\n",
    "                LF_word_predicted_bci[:, 1],\n",
    "                LF_word_predicted_bci[:, 0] < LF_word_predicted_bci[:, 1],  color = \"lightskyblue\", alpha=0.3)\n",
    "\n",
    "axes[0][2].fill_between(quantiles,\n",
    "                NW_word_predicted_bci[:, 0],\n",
    "                NW_word_predicted_bci[:, 1],\n",
    "                NW_word_predicted_bci[:, 0] < NW_word_predicted_bci[:, 1],  color = \"limegreen\", alpha=0.3)\n",
    "\n",
    "\n",
    "axes[1][0].fill_between(quantiles,\n",
    "                HF_nonword_predicted_bci[:, 0],\n",
    "                HF_nonword_predicted_bci[:, 1],\n",
    "                HF_nonword_predicted_bci[:, 0] < HF_nonword_predicted_bci[:, 1],  color = \"gold\", alpha=0.3)\n",
    "\n",
    "axes[1][1].fill_between(quantiles,\n",
    "                LF_nonword_predicted_bci[:, 0],\n",
    "                LF_nonword_predicted_bci[:, 1],\n",
    "                LF_nonword_predicted_bci[:, 0] < LF_nonword_predicted_bci[:, 1],  color = \"lightskyblue\", alpha=0.3)\n",
    "\n",
    "axes[1][2].fill_between(quantiles,\n",
    "                NW_nonword_predicted_bci[:, 0],\n",
    "                NW_nonword_predicted_bci[:, 1],\n",
    "                NW_nonword_predicted_bci[:, 0] < NW_nonword_predicted_bci[:, 1],  color = \"limegreen\", alpha=0.3)\n",
    "\n",
    "\n",
    "for ax_d1 in axes:\n",
    "    for ax in ax_d1:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=18)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RTs upper boundary\", fontsize=18)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label1.set_fontsize(14)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(14) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-Conditional-Word vs Nonword.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fca36-a949-4371-9a61-d81723328db4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Mean Accuracy and RT Posterior Prediction Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce224e-c804-4e47-82b0-4ec2cec6ba95",
   "metadata": {},
   "source": [
    "### All trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e0d51-8b1a-46f6-a440-19122b9fc003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_all_trials_rt, pred_all_trials_rt = get_dfs(behavioural_df, predictedData)\n",
    "exp_all_trials_resp, pred_all_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                    pred_df_type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16b54f-40f4-4973-b313-da2ac5e3a27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data_rt_mean = exp_all_trials_rt[\"rt\"].mean()\n",
    "all_pred_rt_mean = pred_all_trials_rt.mean(axis=1)\n",
    "\n",
    "all_data_resp_mean = exp_all_trials_resp[\"response\"].mean()\n",
    "all_pred_resp_mean = pred_all_trials_resp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3cb73-0684-4a86-baaa-554ee0ae1333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2 , figsize=(12, 4))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"All trials mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[1].set_title(\"All trials mean Response\", fontweight=\"bold\", size=16)\n",
    "\n",
    "plot_mean_posterior(all_pred_rt_mean, all_data_rt_mean, axes[0])\n",
    "plot_mean_posterior(all_pred_resp_mean, all_data_resp_mean, axes[1])\n",
    "\n",
    "axes[0].set_xlabel(\"RT\", fontsize=16)\n",
    "axes[1].set_xlabel(\"Response\", fontsize=16)\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_ylabel(\"Density\", fontsize=16)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "            \n",
    "plt.savefig(plots_path + \"PPC-Mean Accuracy and RT-All trials.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40574c-977b-4269-bb1e-528eaa139c04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All Trials (correct choice vs incorrect choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ce948-7da0-4ea9-b05a-ff496baa2c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_cor_all_trials_rt, pred_cor_all_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                                        accuracy=1)\n",
    "exp_incor_all_trials_rt, pred_incor_all_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                                            accuracy=0)\n",
    "\n",
    "exp_cor_all_trials_resp, pred_cor_all_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                            accuracy=1, pred_df_type=\"response\")\n",
    "exp_incor_all_trials_resp, pred_incor_all_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                                accuracy=0, pred_df_type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3712c389-4ee9-49ba-a1c1-776ef4117124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_trials_cor_rt_mean = exp_cor_all_trials_rt[\"rt\"].mean()\n",
    "all_pred_cor_rt_mean = pred_cor_all_trials_rt.mean(axis=1)\n",
    "\n",
    "all_trials_incor_rt_mean = exp_incor_all_trials_rt[\"rt\"].mean()\n",
    "all_pred_incor_rt_mean = pred_incor_all_trials_rt.mean(axis=1)\n",
    "\n",
    "\n",
    "all_data_cor_resp_mean = exp_cor_all_trials_resp[\"response\"].mean()\n",
    "all_pred_cor_resp_mean = pred_cor_all_trials_resp.mean(axis=1)\n",
    "\n",
    "all_data_incor_resp_mean = exp_incor_all_trials_resp[\"response\"].mean()\n",
    "all_pred_incor_resp_mean = pred_incor_all_trials_resp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977529c-6748-42ff-bcc7-4410ced61b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2 , figsize=(12,10))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "axes[0][0].set_title(\"Correct trials mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[0][1].set_title(\"Correct trials mean Response\", fontweight=\"bold\", size=16)\n",
    "axes[1][0].set_title(\"Incorrect trials mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[1][1].set_title(\"Incorrect trials mean Response\", fontweight=\"bold\", size=16)\n",
    "\n",
    "plot_mean_posterior(all_pred_cor_rt_mean, all_trials_cor_rt_mean, axes[0][0])\n",
    "plot_mean_posterior(all_pred_cor_resp_mean, all_data_cor_resp_mean, axes[0][1])\n",
    "\n",
    "plot_mean_posterior(all_pred_incor_rt_mean, all_trials_incor_rt_mean, axes[1][0])\n",
    "plot_mean_posterior(all_pred_incor_resp_mean, all_data_incor_resp_mean, axes[1][1])\n",
    "\n",
    "for ax in axes:\n",
    "        ax[0].set_xlabel(\"RT\", fontsize=15)\n",
    "        ax[1].set_xlabel(\"Accuracy\", fontsize=15)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=15)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=15)\n",
    "        for tick in ax[0].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[0].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13) \n",
    "\n",
    "plt.savefig(plots_path + \"PPC-Mean Accuracy and RT-All trials-Correct vs Incorrect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07ed4c-9890-45d5-ba73-fe337d76d89c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional (HF, LF, NW trials) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c23f2-b50a-44cf-81ad-1808fcb55376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_HF_trials_rt, pred_HF_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"HF\")\n",
    "exp_LF_trials_rt, pred_LF_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"LF\")\n",
    "exp_NW_trials_rt, pred_NW_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"NW\")\n",
    "\n",
    "exp_HF_trials_resp, pred_HF_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                  category=\"HF\", pred_df_type=\"response\")\n",
    "exp_LF_trials_resp, pred_LF_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                  category=\"LF\", pred_df_type=\"response\")\n",
    "exp_NW_trials_resp, pred_NW_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                  category=\"NW\", pred_df_type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bd273-56cd-45ab-8d2d-b78dd0b5ff44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_data_rt_mean = exp_HF_trials_rt[\"rt\"].mean()\n",
    "LF_data_rt_mean = exp_LF_trials_rt[\"rt\"].mean()\n",
    "NW_data_rt_mean = exp_NW_trials_rt[\"rt\"].mean()\n",
    "\n",
    "HF_pred_rt_mean = pred_HF_trials_rt.mean(axis=1)\n",
    "LF_pred_rt_mean = pred_LF_trials_rt.mean(axis=1)\n",
    "NW_pred_rt_mean = pred_NW_trials_rt.mean(axis=1)\n",
    "\n",
    "\n",
    "HF_data_resp_mean = exp_HF_trials_resp[\"response\"].mean()\n",
    "LF_data_resp_mean = exp_LF_trials_resp[\"response\"].mean()\n",
    "NW_data_resp_mean = exp_NW_trials_resp[\"response\"].mean()\n",
    "\n",
    "HF_pred_resp_mean = pred_HF_trials_resp.mean(axis=1)\n",
    "LF_pred_resp_mean = pred_LF_trials_resp.mean(axis=1)\n",
    "NW_pred_resp_mean = pred_NW_trials_resp.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1425b94-db06-4d73-a4d5-ce1b342856a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2 , figsize=(12,15))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "axes[0][0].set_title(\"HF mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[0][1].set_title(\"HF mean Response\", fontweight=\"bold\", size=16)\n",
    "axes[1][0].set_title(\"LF mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[1][1].set_title(\"LF mean Response\", fontweight=\"bold\", size=16)\n",
    "axes[2][0].set_title(\"NW mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[2][1].set_title(\"NW mean Response\", fontweight=\"bold\", size=16)\n",
    "\n",
    "plot_mean_posterior(HF_pred_rt_mean, HF_data_rt_mean, axes[0][0])\n",
    "plot_mean_posterior(HF_pred_resp_mean, HF_data_resp_mean, axes[0][1])\n",
    "\n",
    "plot_mean_posterior(LF_pred_rt_mean, LF_data_rt_mean, axes[1][0])\n",
    "plot_mean_posterior(LF_pred_resp_mean, LF_data_resp_mean, axes[1][1])\n",
    "\n",
    "plot_mean_posterior(NW_pred_rt_mean, NW_data_rt_mean, axes[2][0])\n",
    "plot_mean_posterior(NW_pred_resp_mean, NW_data_resp_mean, axes[2][1])\n",
    "\n",
    "for ax in axes:\n",
    "        ax[0].set_xlabel(\"RT\", fontsize=15)\n",
    "        ax[1].set_xlabel(\"Accuracy\", fontsize=15)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=15)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=15)\n",
    "        for tick in ax[0].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[0].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13) \n",
    "\n",
    "plt.savefig(plots_path + \"PPC-Mean Accuracy and RT-Conditional.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124c569-b5c7-4192-a1e2-cabe6856c323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740a45d-3753-4152-8256-2dbda204a17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1640d-cd08-464e-89e4-f56d91bf017f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c98d8-695d-4f15-9e0c-b8c9b21be456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Estimation_Hier.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "stan",
   "language": "python",
   "name": "stan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
